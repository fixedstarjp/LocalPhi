# AI Assistant Chrome Extension

ローカル環境のPhi-4 miniモデルを使用したChrome拡張機能です。

## 機能

### 🤖 チャットインターフェース
- Phi-4 miniモデルとの対話
- リアルタイムな応答
- 自然な会話形式

### 📊 ウェブページ分析
- 現在のページのテキスト分析
- 要約機能
- 重要なポイントの抽出

### 🌐 翻訳機能
- 選択したテキストの日本語翻訳
- コンテキストメニューからの翻訳
- 高精度な翻訳結果

## 技術スタック

- **WebLLM**: ブラウザ内LLM推論
- **Phi-4 Mini**: Microsoft製の高性能小型LLM
- **Chrome Extension API**: Manifest V3
- **JavaScript**: バニラJS（依存関係なし）

## インストール方法

1. Chrome拡張機能の開発者モードを有効にする
2. 「拡張機能をパッケージ化されていない状態で読み込む」を選択
3. `/app/chrome-extension`フォルダを選択
4. 拡張機能アイコンをクリックして使用開始

## 使用方法

### チャット
1. 拡張機能アイコンをクリック
2. 「チャット」タブを選択
3. メッセージを入力してEnterキーまたは送信ボタンをクリック

### ページ分析
1. 分析したいウェブページを開く
2. 拡張機能で「分析」タブを選択
3. 「現在のページを分析する」または「現在のページを要約する」をクリック

### 翻訳
1. 翻訳したいテキストを選択
2. 拡張機能で「翻訳」タブを選択
3. 「選択したテキストを翻訳する」をクリック

## 現在の実装状況

⚠️ **現在はモック実装です**

実際のWebLLMとPhi-4 miniモデルの統合は次の段階で行います。
現在のバージョンでは、以下の機能がモックとして実装されています：

- モデル読み込みシミュレーション
- チャット応答のモック
- 分析・翻訳結果のモック
- 完全なUIとUX体験

## 次のステップ

1. **WebLLMライブラリの統合**
   - `@mlc-ai/web-llm`パッケージの導入
   - Phi-4 miniモデルの読み込み設定

2. **実際のAI推論の実装**
   - モック応答から実際のモデル推論への移行
   - パフォーマンス最適化

3. **機能拡張**
   - より高度な分析機能
   - 多言語翻訳対応
   - カスタムプロンプト設定

## 技術的な詳細

### ファイル構造
```
/app/chrome-extension/
├── manifest.json      # 拡張機能の設定
├── popup.html        # メインUI
├── popup.js          # UI制御とWebLLM統合
├── background.js     # バックグラウンドプロセス
├── content.js        # ウェブページとの相互作用
└── README.md         # この文書
```

### 権限
- `storage`: 設定とチャット履歴の保存
- `activeTab`: 現在のタブの情報取得
- `scripting`: ページコンテンツの解析
- `contextMenus`: 右クリックメニューの追加

## 開発について

このプロジェクトは、プライバシーを重視したローカルAI推論を実現するChrome拡張機能です。サーバーにデータを送信せず、すべての処理をブラウザ内で完結させます。